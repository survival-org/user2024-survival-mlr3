{
  "hash": "11fd43c212f525360874038cc9cdbebb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intro to Machine Learning for Survival Analysis with mlr3\"\nauthor: \"[John Zobolas](https://github.com/bblodfon), [Lukas Burk](https://lukasburk.de/)\"\ndate: last-modified\ndescription: \"Tutorial for the useR! 2024 conference in Salzburg, Austria (8-11 July)\"\nformat:\n  html:\n    date: last-modified\n    code-block-bg: true\n    code-copy: true\n    code-fold: show\n    code-overflow: wrap\n    code-block-border-left: true\n    toc: true\n    toc-location: left\n    html-math-method: katex\n    page-layout: full\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n\n## `mlr3`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand how `{mlr3}` is structured\n- Access `learner`s and (built-in) `task`s\n:::\n\nTo get started, we load `{mlr3verse}`, which will load various packages from the `{mlr3}` ecosystem:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\n\n\n`{mlr3}` ships with wrappers for many commonly used machine learning algorithms (\"learners\").  \nWe can access the list of available learners using the `mlr_learners` dictionary:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(mlr_learners$keys(), 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"surv.cv_glmnet\"  \"regr.kknn\"       \"clust.hdbscan\"   \"surv.gbm\"       \n [5] \"classif.J48\"     \"clust.em\"        \"surv.coxboost\"   \"surv.parametric\"\n [9] \"classif.log_reg\" \"regr.glmnet\"    \n```\n\n\n:::\n:::\n\n\n\n\nOne example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn(\"classif.ranger\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<LearnerClassifRanger:classif.ranger>: Random Forest\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nUse `lrn(\"classif.ranger\")$help()` to view the help page, with links to documentation for parameters and other information about the wrapped learner.\n:::\n\nBuilt-in tasks can be accessed using the `mlr_tasks` dictionary:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_tasks)[, list(key, label, task_type, nrow, ncol, properties)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <key>\n              key                     label task_type  nrow  ncol properties\n           <char>                    <char>    <char> <int> <int>     <list>\n1:   ames_housing          Ames House Sales      regr  2930    82           \n2:   bike_sharing       Bike Sharing Demand      regr 17379    14           \n3: boston_housing     Boston Housing Prices      regr   506    18           \n4:  breast_cancer   Wisconsin Breast Cancer   classif   683    10   twoclass\n5:  german_credit             German Credit   classif  1000    21   twoclass\n6:           ilpd Indian Liver Patient Data   classif   583    11   twoclass\n```\n\n\n:::\n:::\n\n\n\n\nOne example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntsk(\"penguins_simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskClassif:penguins> (333 x 11): Simplified Palmer Penguins\n* Target: species\n* Properties: multiclass\n* Features (10):\n  - dbl (7): bill_depth, bill_length, island.Biscoe, island.Dream,\n    island.Torgersen, sex.female, sex.male\n  - int (3): body_mass, flipper_length, year\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nTasks encapsulate a data source (typically a `data.table`) and additional information regarding which variables are considered features and target.\nTasks can also specify additional properties such as stratification, which we will see later.\n:::\n\n## Example: Train-Predict-Evaluate {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Perform a simple train-predict-evaluate step\n- Use built-in classification `task` and `learner`\n:::\n\nThe below code snippet trains a random forest model on the `penguins_simple` task (a simplified version of the `palmerpenguins` dataset, but without missing values) and evaluates the model's performance using the classification error metric:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = tsk(\"penguins_simple\")\nlearner = lrn(\"classif.ranger\", num.trees = 10)\n\npart = partition(task, ratio = 0.8) # by default stratifies on the target column\n\nlearner$train(task, row_ids = part$train)\npreds = learner$predict(task, row_ids = part$test)\npreds$score(msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.ce \n0.01492537 \n```\n\n\n:::\n:::\n\n\n\n\n## `mlr3proba`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand survival tasks and how they differ from regression/classification\n- Know how to conduct basic modeling with `{mlr3proba}`\n- Prediction types\n- Survival measures\n:::\n\n`{mlr3proba}` extends `{mlr3}` with survival analysis capabilities.\n\n:::{.callout-important}\nAs of now, `{mlr3proba}` is not on CRAN, but you can install it [from GitHub](https://github.com/mlr-org/mlr3proba/?tab=readme-ov-file#installation) or [r-universe](https://mlr-org.r-universe.dev/mlr3proba).\nMore info is also available on the respective [mlr3 book chapter](https://mlr3book.mlr-org.com/chapters/chapter13/beyond_regression_and_classification.html#sec-survival).\n:::\n\n### Survival Tasks {-}\n\nWe'll start by using the built-in `lung` dataset, which is a survival task with $7$ features and $168$ observations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3proba)\ntask = tsk(\"lung\")\n\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskSurv:lung> (168 x 9): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (7):\n  - int (6): age, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - fct (1): sex\n```\n\n\n:::\n:::\n\n\n\n\n[See online reference](https://mlr3proba.mlr-org.com/reference/TaskSurv.html#methods) to useful methods offered by the main `TaskSurv` class.\nSome examples:\n\nTarget `Surv` object from `{survival}` (`+` denotes censored observation):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(task$truth())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  455   210  1022+  310   361   218 \n```\n\n\n:::\n:::\n\n\n\n\nProportion of censored observations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$cens_prop()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2797619\n```\n\n\n:::\n:::\n\n\n\n\nDoes the data satisfy the **proportional hazards** assumption? Get the p-value from the Grambsch-Therneau test (see `?survival::cox.zph`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$prop_haz() # barely, p > 0.05 => PH\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0608371\n```\n\n\n:::\n:::\n\n\n\n\nUsing the `autoplot()` function from `{ggplot2}`, we get the Kaplan-Meier curve:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nautoplot(task) +\n  labs(title = \"Lung dataset: Kaplan-Meier curve\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/km-curve-1.png){width=672}\n:::\n:::\n\n\n\n\nTasks shipped with `{mlr3proba}`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(mlr_tasks)[task_type == \"surv\", list(key, label, nrow, ncol)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <key>\n             key                       label  nrow  ncol\n          <char>                      <char> <int> <int>\n 1:         actg                    ACTG 320  1151    13\n 2:         gbcs        German Breast Cancer   686    10\n 3:         gbsg        German Breast Cancer   686    10\n 4:        grace                  GRACE 1000  1000     8\n 5:         lung                 Lung Cancer   168     9\n 6:         mgus                        MGUS   176     9\n 7:          pbc Primary Biliary Cholangitis   276    19\n 8:         rats                        Rats   300     5\n 9: unemployment       Unemployment Duration  3343     6\n10:      veteran                     Veteran   137     8\n11:         whas      Worcester Heart Attack   481    11\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\n- Use [as_task_surv()](https://mlr3proba.mlr-org.com/reference/as_task_surv.html) to convert your own datasets to a `TaskSurv` object\n- Try `tsk(\"lung\")$help()` to get more info about the dataset and pre-processing applied\n:::\n\n### CoxPH learner {-}\n\nThe classical Cox Proportional Hazards model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncox = lrn(\"surv.coxph\")\ncox\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<LearnerSurvCoxPH:surv.coxph>: Cox Proportional Hazards\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  [crank], distr, lp\n* Feature Types: logical, integer, numeric, factor\n* Properties: weights\n```\n\n\n:::\n:::\n\n\n\n\nTrain the cox model and access the fit object from the `{survival}` package:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\npart = partition(task, ratio = 0.8) # by default, stratification is on `status` variable\ncox$train(task, row_ids = part$train)\n\ncox$model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nsurvival::coxph(formula = task$formula(), data = task$data(), \n    x = TRUE)\n\n                coef  exp(coef)   se(coef)      z      p\nage        1.341e-02  1.013e+00  1.258e-02  1.066 0.2864\nmeal.cal  -5.007e-05  9.999e-01  2.903e-04 -0.172 0.8631\npat.karno -2.142e-02  9.788e-01  9.055e-03 -2.366 0.0180\nph.ecog    5.936e-01  1.811e+00  2.500e-01  2.375 0.0176\nph.karno   2.541e-02  1.026e+00  1.263e-02  2.011 0.0443\nsexm       4.510e-01  1.570e+00  2.298e-01  1.962 0.0497\nwt.loss   -1.500e-02  9.851e-01  8.395e-03 -1.787 0.0739\n\nLikelihood ratio test=23.36  on 7 df, p=0.001475\nn= 135, number of events= 97 \n```\n\n\n:::\n:::\n\n\n\n\nVisual output of the model, using the latest version from Github of `{mlr3viz}`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(cox)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/cox-model-viz-1.png){width=672}\n:::\n:::\n\n\n\n\n### Prediction types {-}\n\nLet's predict using the trained cox model on the test set (output is a [PredictionSurv](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) object):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np = cox$predict(task, row_ids = part$test)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<PredictionSurv> for 33 observations:\n    row_ids time status       crank          lp     distr\n          1  455   TRUE -0.16022736 -0.16022736 <list[1]>\n          8  170   TRUE  0.07608537  0.07608537 <list[1]>\n         15  371   TRUE -0.46601841 -0.46601841 <list[1]>\n---                                                      \n        165  191  FALSE -0.30526841 -0.30526841 <list[1]>\n        166  105  FALSE  0.49632782  0.49632782 <list[1]>\n        168  177  FALSE -0.17234336 -0.17234336 <list[1]>\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip title=\"Prediction types in mlr3proba\"}\n- `crank`: Continuous risk ranking\n- `lp`: Linear predictor calculated as $\\hat\\beta * X_{test}$\n- `distr`: Predicted survival distribution, either discrete or continuous\n- `response`: Predicted survival time\n:::\n\nFor the cox model, `crank = lp` (the higher, the more risk):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$lp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           1            2            3            4            5            6 \n-0.160227364  0.076085366 -0.466018411  0.293380270  1.179147761  0.523244848 \n           7            8            9           10           11           12 \n 0.391564618 -0.029833700 -0.149489235 -0.262762070  0.076021387  0.279388934 \n          13           14           15           16           17           18 \n 0.889995280  0.859467193  1.030472975  0.277533930 -0.057165655  0.362416853 \n          19           20           21           22           23           24 \n-0.037670338 -0.295071061 -0.419840184  0.793214751  0.823500785  0.977222024 \n          25           26           27           28           29           30 \n-0.046252611  0.021227170 -0.093541236 -0.158438686  1.615114453  0.003701068 \n          31           32           33 \n-0.305268413  0.496327822 -0.172343361 \n```\n\n\n:::\n:::\n\n\n\n\nSurvival prediction is a 2D `matrix` essentially, with dimensions: *observations* x *time points*:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$data$distr[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          5        11        12        13        15\n1 0.9959775 0.9919519 0.9879072 0.9837970 0.9796477\n2 0.9949079 0.9898175 0.9847084 0.9795222 0.9742926\n3 0.9970357 0.9940659 0.9910789 0.9880402 0.9849691\n4 0.9936759 0.9873617 0.9810323 0.9746156 0.9681535\n5 0.9847342 0.9696296 0.9546262 0.9395560 0.9245212\n```\n\n\n:::\n:::\n\n\n\n\nUsers should use the [distr6](https://github.com/xoopR/distr6) interface to access this prediction type, which allows us to retrieve survival probabilities (or hazards) for any time point of interest:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first 4 patients in the test set, specific time points:\np$distr[1:4]$survival(c(100, 500, 1200))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]      [,3]       [,4]\n100  0.9184997 0.8979186 0.9393041 0.87475634\n500  0.4589611 0.3729197 0.5634874 0.29352281\n1200 0.1684876 0.1048078 0.2693617 0.06062239\n```\n\n\n:::\n:::\n\n\n\n\nVisualization of predicted survival curves for $3$ test patients:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 = p$clone()$filter(row_ids = c(1,24,40))\nautoplot(p2, type = \"preds\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pred-curves-1.png){width=672}\n:::\n:::\n\n\n\n\n### Model evaluation {-}\n\n:::{.callout-tip title=\"Model validation\"}\nValidation of a survival model can be done by assessing:\n\n1. **Discrimination**: the ability of the model to distinguish between low and high risk patients\n2. **Calibration**: the agreement between the observed and predicted survival probabilities\n3. **Overall performance**: the distance between the observed and predicted survival probabilities\n:::\n\nMany measures included in `mlr3proba`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_measures$keys(pattern = \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"surv.brier\"         \"surv.calib_alpha\"   \"surv.calib_beta\"   \n [4] \"surv.chambless_auc\" \"surv.cindex\"        \"surv.dcalib\"       \n [7] \"surv.graf\"          \"surv.hung_auc\"      \"surv.intlogloss\"   \n[10] \"surv.logloss\"       \"surv.mae\"           \"surv.mse\"          \n[13] \"surv.nagelk_r2\"     \"surv.oquigley_r2\"   \"surv.rcll\"         \n[16] \"surv.rmse\"          \"surv.schmid\"        \"surv.song_auc\"     \n[19] \"surv.song_tnr\"      \"surv.song_tpr\"      \"surv.uno_auc\"      \n[22] \"surv.uno_tnr\"       \"surv.uno_tpr\"       \"surv.xu_r2\"        \n```\n\n\n:::\n:::\n\n\n\n\nMost commonly used metrics are for assessing discrimination, such as **Harrell's C-index**, **Uno's C-index** and the **(time-dependent) AUC**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nharrell_c = msr(\"surv.cindex\", id = \"surv.cindex.harrell\")\nuno_c = msr(\"surv.cindex\", weight_meth = \"G2\", id = \"surv.cindex.uno\")\nuno_auci = msr(\"surv.uno_auc\", integrated = TRUE) # across all times in the test set\nuno_auc = msr(\"surv.uno_auc\", integrated = FALSE, times = 10) # at a specific time-point of interest\n\nharrell_c\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvCindex:surv.cindex.harrell>\n* Packages: mlr3, mlr3proba\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: weight_meth=I, tiex=0.5, eps=0.001\n* Properties: -\n* Predict type: crank\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\nuno_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvUnoAUC:surv.uno_auc>\n* Packages: mlr3, mlr3proba, survAUC\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: integrated=FALSE, times=10\n* Properties: requires_task, requires_train_set\n* Predict type: lp\n* Return type: Score\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\n- Not all measures are applicable to all models - **prediction type** matters!\n- Most discrimination metrics use the `crank` or `lp` prediction\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$score(harrell_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.cindex.harrell \n          0.6336898 \n```\n\n\n:::\n\n```{.r .cell-code}\np$score(uno_c, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.cindex.uno \n      0.5907828 \n```\n\n\n:::\n:::\n\n\n\n\nCalibration is traditionally performed graphically via calibration plots:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(p, type = \"calib\", task = task, row_ids = part$test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/calib-plot-1.png){width=672}\n:::\n:::\n\n\n\n\nBut there exists also calibration metrics, e.g. **D-Calibration**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcal = msr(\"surv.dcalib\")\ndcal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvDCalibration:surv.dcalib>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: B=10, chisq=FALSE, truncate=Inf\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(dcal)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.dcalib \n   8.320423 \n```\n\n\n:::\n:::\n\n\n\n\nOverall survival prediction performance can be assessed by scoring rules such as the **Integrated Survival Brier Score** (ISBS) and the **Right-censored Log-Loss** (RCLL) among others:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcll = msr(\"surv.rcll\")\nrcll\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvRCLL:surv.rcll>\n* Packages: mlr3, mlr3proba, distr6\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: eps=1e-15, se=FALSE, ERV=FALSE, na.rm=TRUE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(rcll)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.rcll \n 23.46684 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nibrier = msr(\"surv.brier\", proper = TRUE)\nibrier\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvGraf:surv.graf>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: integrated=TRUE, method=2, se=FALSE, proper=TRUE,\n  eps=0.001, ERV=FALSE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(ibrier, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.graf \n0.1591112 \n```\n\n\n:::\n:::\n\n\n\n\n### Using ML survival models {-}\n\nSo far we have used the Cox regression model, but there are many more machine learning methods available via `mlr3extralearners`!\nWe will take a look at the following:\n\n- Cox elastic net via [`glmnet`](https://glmnet.stanford.edu/articles/Coxnet.html)\n  - We will use `lrn(\"surv.cv_glmnet\")`, wich internally tunes for `lambda` using cross-validation\n- Likelihood-based boosting via [`CoxBoost`](https://github.com/binderh/CoxBoost)\n  - We will use `lrn(\"surv.cv_coxboost\", penalty = \"optimCoxBoostPenalty\")`, which also uses internal cross-validation to tune its parameters\n- Random Forests via [`ranger`](https://imbs-hl.github.io/ranger/)\n- Oblique Random Forests via [`aorsf`](https://docs.ropensci.org/aorsf/)\n\nThese learners then cover the range from penalized regression to tree ensembles and boosting.\n\n## Benchmark example: GEX + clinical data {-}\n\n- From the tutorial (https://ocbe-uio.github.io/survomics/survomics.html#workflow)\n- data => https://github.com/ocbe-uio/survomics/blob/main/data.rds\n- Benchmark + posthoc analysis of results with `mlr3benchmark`\n\nIn this example we'll take a few learners for a spin on a subset of TCGA\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntcga = readRDS(\"data/tcga.rds\")\n\ntask_tcga <- mlr3proba::as_task_surv(\n  x = tcga, \n  time = \"time\", event = \"status\", id = \"BRCA-TCGA\"\n)\n\n# Set stratum for resampling\ntask$set_col_roles(\"status\", add_to = \"stratum\")\n```\n:::\n\n\n\n\nFirst we instantiate our learners as we've seen before --- we're sticking to mostly vanilla settings for now.  \nWe let `glmnet` determine the optimal value for `lambda` with it's internal cross-validation method, and we similarly let `CoxBoost` to the same with it's `optimCoxBoostPenalty` method to determine the penalty and boosting iterations.\nFor the forests, we use 100 trees each and otherwise accept the defaults.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn_glmnet = lrn(\"surv.cv_glmnet\", alpha = 0.5)\nlrn_coxboost = lrn(\"surv.cv_coxboost\", penalty = \"optimCoxBoostPenalty\", maxstepno = 1000)\nlrn_ranger = lrn(\"surv.ranger\", num.trees = 100)\nlrn_aorsf = lrn(\"surv.aorsf\", n_tree = 100)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndesign = benchmark_grid(\n  tasks = task_tcga,\n  learners = list(lrn_glmnet, lrn_ranger, lrn_aorsf, lrn_coxboost),\n  resamplings = rsmp(\"cv\", folds = 3)\n)\n\ndesign\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        task          learner resampling\n      <char>           <char>     <char>\n1: BRCA-TCGA   surv.cv_glmnet         cv\n2: BRCA-TCGA      surv.ranger         cv\n3: BRCA-TCGA       surv.aorsf         cv\n4: BRCA-TCGA surv.cv_coxboost         cv\n```\n\n\n:::\n:::\n\n\n\n\nTo actually run the benchmark, we're going to make use of the `future` package used throughout the `mlr3` ecosystem.\nYou may want to change `plan(\"multisession\")` to a different strategy, but regardless of your platform you will need to set `workers = 4` to the number of cores you can spare.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfuture::plan(\"multisession\", workers = 6)\n\nbmr = benchmark(design, store_models = TRUE, store_backends = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:13:33.477] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [17:13:34.361] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:13:35.277] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:13:36.130] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:13:36.962] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:13:37.840] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:13:38.713] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:13:38.712] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:13:38.756] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:13:38.804] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:13:38.904] [mlr3] Applying learner 'surv.cv_coxboost' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:13:38.985] [mlr3] Applying learner 'surv.cv_coxboost' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:13:39.066] [mlr3] Applying learner 'surv.cv_coxboost' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:14:50.513] [mlr3] Finished benchmark\n```\n\n\n:::\n\n```{.r .cell-code}\nbmr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<BenchmarkResult> of 12 rows with 4 resampling runs\n nr   task_id       learner_id resampling_id iters warnings errors\n  1 BRCA-TCGA   surv.cv_glmnet            cv     3        0      0\n  2 BRCA-TCGA      surv.ranger            cv     3        0      0\n  3 BRCA-TCGA       surv.aorsf            cv     3        0      0\n  4 BRCA-TCGA surv.cv_coxboost            cv     3        0      0\n```\n\n\n:::\n:::\n\n\n\n\nWith our benchmark results in hand, we can now aggregate them to get a summary of the performance of our learners across all tasks and resamplings.\n\nWe first pick two measures: Harrell's C and the integrated brier score, and then\n\n1. Score each individual resampling iteration using `$score()`, which gives us one score for each iteration\n2. Aggregate these scores using `$aggregate()`, which gives us a summary of the performance of each learner across all resamplings.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasures = list(\n  harrell_c = msr(\"surv.cindex\"),\n  ibs = msr(\"surv.brier\")\n)\n\nscores = bmr$score(measures)\nscores\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       nr   task_id       learner_id resampling_id iteration surv.cindex\n    <int>    <char>           <char>        <char>     <int>       <num>\n 1:     1 BRCA-TCGA   surv.cv_glmnet            cv         1   0.5000000\n 2:     1 BRCA-TCGA   surv.cv_glmnet            cv         2   0.5000000\n 3:     1 BRCA-TCGA   surv.cv_glmnet            cv         3   0.5000000\n 4:     2 BRCA-TCGA      surv.ranger            cv         1   0.6704925\n 5:     2 BRCA-TCGA      surv.ranger            cv         2   0.6528650\n 6:     2 BRCA-TCGA      surv.ranger            cv         3   0.5469275\n 7:     3 BRCA-TCGA       surv.aorsf            cv         1   0.6869098\n 8:     3 BRCA-TCGA       surv.aorsf            cv         2   0.6106585\n 9:     3 BRCA-TCGA       surv.aorsf            cv         3   0.5334988\n10:     4 BRCA-TCGA surv.cv_coxboost            cv         1   0.6452128\n11:     4 BRCA-TCGA surv.cv_coxboost            cv         2   0.6396421\n12:     4 BRCA-TCGA surv.cv_coxboost            cv         3   0.6187418\n    surv.graf\n        <num>\n 1: 0.1756614\n 2: 0.1324771\n 3: 0.2651273\n 4: 0.2229598\n 5: 0.1407388\n 6: 0.2849396\n 7: 0.2137103\n 8: 0.1331422\n 9: 0.2628250\n10: 0.2009297\n11: 0.1302240\n12: 0.2544661\nHidden columns: uhash, task, learner, resampling, prediction\n```\n\n\n:::\n\n```{.r .cell-code}\naggr = bmr$aggregate(measures)\naggr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      nr   task_id       learner_id resampling_id iters surv.cindex surv.graf\n   <int>    <char>           <char>        <char> <int>       <num>     <num>\n1:     1 BRCA-TCGA   surv.cv_glmnet            cv     3   0.5000000 0.1910886\n2:     2 BRCA-TCGA      surv.ranger            cv     3   0.6234283 0.2162127\n3:     3 BRCA-TCGA       surv.aorsf            cv     3   0.6103557 0.2032258\n4:     4 BRCA-TCGA surv.cv_coxboost            cv     3   0.6345322 0.1952066\nHidden columns: resample_result\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}