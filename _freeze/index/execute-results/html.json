{
  "hash": "e45884686c9f6734b0d139e8a1fde5b6",
  "result": {
    "markdown": "---\ntitle: \"Intro to Machine Learning for Survival Analysis with mlr3\"\nauthor: \"[John Zobolas](https://github.com/bblodfon), [Lukas Burk](https://lukasburk.de/)\"\ndate: last-modified\ndescription: \"Tutorial for the useR! 2024 conference in Salzburg, Austria (8-11 July)\"\nformat:\n  html:\n    date: last-modified\n    code-block-bg: true\n    code-copy: true\n    code-fold: show\n    code-overflow: wrap\n    code-block-border-left: true\n    toc: true\n    toc-location: left\n    html-math-method: katex\n    page-layout: full\nexecute:\n  freeze: true\n---\n\n\n\n\n## `mlr3`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand how `{mlr3}` is structured\n- Access `learner`s and (built-in) `task`s\n:::\n\nTo get started, we load `{mlr3verse}`, which will load various packages from the `{mlr3}` ecosystem:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\n`{mlr3}` ships with wrappers for many commonly used machine learning algorithms (\"learners\").  \nWe can access the list of available learners using the `mlr_learners` dictionary:\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(mlr_learners$keys(), 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"classif.randomForest\" \"surv.penalized\"       \"regr.lm\"             \n [4] \"clust.meanshift\"      \"surv.cv_glmnet\"       \"regr.ranger\"         \n [7] \"regr.svm\"             \"clust.featureless\"    \"surv.mboost\"         \n[10] \"regr.lightgbm\"       \n```\n:::\n:::\n\n\nOne example:\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn(\"classif.ranger\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRanger:classif.ranger>: Random Forest\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n:::\n:::\n\n\n:::{.callout-note}\nUse `lrn(\"classif.ranger\")$help()` to view the help page, with links to documentation for parameters and other information about the wrapped learner.\n:::\n\nBuilt-in tasks can be accessed using the `mlr_tasks` dictionary:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_tasks)[, list(key, label, task_type, nrow, ncol, properties)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKey: <key>\n              key                     label task_type  nrow  ncol properties\n           <char>                    <char>    <char> <int> <int>     <list>\n1:   ames_housing          Ames House Sales      regr  2930    82           \n2:   bike_sharing       Bike Sharing Demand      regr 17379    14           \n3: boston_housing     Boston Housing Prices      regr   506    18           \n4:  breast_cancer   Wisconsin Breast Cancer   classif   683    10   twoclass\n5:  german_credit             German Credit   classif  1000    21   twoclass\n6:           ilpd Indian Liver Patient Data   classif   583    11   twoclass\n```\n:::\n:::\n\n\nOne example:\n\n::: {.cell}\n\n```{.r .cell-code}\ntsk(\"penguins_simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:penguins> (333 x 11): Simplified Palmer Penguins\n* Target: species\n* Properties: multiclass\n* Features (10):\n  - dbl (7): bill_depth, bill_length, island.Biscoe, island.Dream,\n    island.Torgersen, sex.female, sex.male\n  - int (3): body_mass, flipper_length, year\n```\n:::\n:::\n\n\n:::{.callout-note}\nTasks encapsulate a data source (typically a `data.table`) and additional information regarding which variables are considered features and target.\nTasks can also specify additional properties such as stratification, which we will see later.\n:::\n\n## Example: Train-Predict-Evaluate {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Perform a simple train-predict-evaluate step\n- Use built-in classification `task` and `learner`\n:::\n\nThe below code snippet trains a random forest model on the `penguins_simple` task (a simplified version of the `palmerpenguins` dataset, but without missing values) and evaluates the model's performance using the classification error metric:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = tsk(\"penguins_simple\")\nlearner = lrn(\"classif.ranger\", num.trees = 10)\n\npart = partition(task, ratio = 0.8) # by default stratifies on the target column\n\nlearner$train(task, row_ids = part$train)\npreds = learner$predict(task, row_ids = part$test)\npreds$score(msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n0.01492537 \n```\n:::\n:::\n\n\n## `mlr3proba`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand survival tasks and how they differ from regression/classification\n- Know how to conduct basic modeling with `{mlr3proba}`\n- Prediction types\n- Survival measures\n:::\n\n`{mlr3proba}` extends `{mlr3}` with survival analysis capabilities.\n\n:::{.callout-important}\nAs of now, `{mlr3proba}` is not on CRAN, but you can install it [from GitHub](https://github.com/mlr-org/mlr3proba/?tab=readme-ov-file#installation) or [r-universe](https://mlr-org.r-universe.dev/mlr3proba).\nMore info is also available on the respective [mlr3 book chapter](https://mlr3book.mlr-org.com/chapters/chapter13/beyond_regression_and_classification.html#sec-survival).\n:::\n\n### Survival Tasks {-}\n\nWe'll start by using the built-in `lung` dataset, which is a survival task with $7$ features and $168$ observations:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3proba)\ntask = tsk(\"lung\")\n\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskSurv:lung> (168 x 9): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (7):\n  - int (6): age, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - fct (1): sex\n```\n:::\n:::\n\n\n[See online reference](https://mlr3proba.mlr-org.com/reference/TaskSurv.html#methods) to useful methods offered by the main `TaskSurv` class.\nSome examples:\n\nTarget `Surv` object from `{survival}` (`+` denotes censored observation):\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(task$truth())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  455   210  1022+  310   361   218 \n```\n:::\n:::\n\n\nProportion of censored observations:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$cens_prop()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2797619\n```\n:::\n:::\n\n\nDoes the data satisfy the **proportional hazards** assumption? Get the p-value from the Grambsch-Therneau test:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$prop_haz() # barely, p > 0.05 => PH\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0608371\n```\n:::\n:::\n\n\nUsing the `autoplot()` function from `{ggplot2}`, we get the Kaplan-Meier curve:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nautoplot(task) +\n  labs(title = \"Lung dataset: Kaplan-Meier curve\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nTasks shipped with `{mlr3proba}`:\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(mlr_tasks)[task_type == \"surv\", list(key, label, nrow, ncol)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKey: <key>\n             key                       label  nrow  ncol\n          <char>                      <char> <int> <int>\n 1:         actg                    ACTG 320  1151    13\n 2:         gbcs        German Breast Cancer   686    10\n 3:         gbsg        German Breast Cancer   686    10\n 4:        grace                  GRACE 1000  1000     8\n 5:         lung                 Lung Cancer   168     9\n 6:         mgus                        MGUS   176     9\n 7:          pbc Primary Biliary Cholangitis   276    19\n 8:         rats                        Rats   300     5\n 9: unemployment       Unemployment Duration  3343     6\n10:      veteran                     Veteran   137     8\n11:         whas      Worcester Heart Attack   481    11\n```\n:::\n:::\n\n\n:::{.callout-note}\n- Use [as_task_surv()](https://mlr3proba.mlr-org.com/reference/as_task_surv.html) to convert your own datasets to a `TaskSurv` object\n- Try `tsk(\"lung\")$help()` to get more info about the dataset and pre-processing applied\n:::\n\n### CoxPH learner {-}\n\nThe classical Cox Proportional Hazards model:\n\n::: {.cell}\n\n```{.r .cell-code}\ncox = lrn(\"surv.coxph\")\ncox\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerSurvCoxPH:surv.coxph>: Cox Proportional Hazards\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  [crank], distr, lp\n* Feature Types: logical, integer, numeric, factor\n* Properties: weights\n```\n:::\n:::\n\n\nTrain the cox model and access the fit object from the `{survival}` package:\n\n::: {.cell}\n\n```{.r .cell-code}\npart = partition(task, ratio = 0.8) # by default, stratification is on `status` variable\ncox$train(task, row_ids = part$train)\n\ncox$model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nsurvival::coxph(formula = task$formula(), data = task$data(), \n    x = TRUE)\n\n                coef  exp(coef)   se(coef)      z        p\nage        0.0072037  1.0072297  0.0126836  0.568 0.570069\nmeal.cal  -0.0001913  0.9998087  0.0003387 -0.565 0.572193\npat.karno -0.0084326  0.9916029  0.0093169 -0.905 0.365418\nph.ecog    0.9070317  2.4769592  0.2492998  3.638 0.000274\nph.karno   0.0274085  1.0277875  0.0120926  2.267 0.023418\nsexm       0.6708008  1.9558029  0.2266265  2.960 0.003077\nwt.loss   -0.0205576  0.9796522  0.0101108 -2.033 0.042030\n\nLikelihood ratio test=27.92  on 7 df, p=0.0002273\nn= 135, number of events= 97 \n```\n:::\n:::\n\n\nVisual output of the model, using the latest version from Github of `{mlr3viz}`:\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(cox)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### Prediction types {-}\n\nLet's predict using the trained cox model on the test set (output is a [PredictionSurv](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) object):\n\n::: {.cell}\n\n```{.r .cell-code}\np = cox$predict(task, row_ids = part$test)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionSurv> for 33 observations:\n    row_ids time status        crank           lp     distr\n          9  567   TRUE -0.700201337 -0.700201337 <list[1]>\n         10  613   TRUE  1.028226970  1.028226970 <list[1]>\n         28  731   TRUE -0.375816571 -0.375816571 <list[1]>\n---                                                        \n        163  197  FALSE  0.605988685  0.605988685 <list[1]>\n        167  174  FALSE  0.890416067  0.890416067 <list[1]>\n        168  177  FALSE -0.004345193 -0.004345193 <list[1]>\n```\n:::\n:::\n\n\n:::{.callout-tip title=\"Prediction types in mlr3proba\"}\n- `crank`: Continuous risk ranking\n- `lp`: Linear predictor calculated as $\\hat\\beta * X_{test}$\n- `distr`: Predicted survival distribution, either discrete or continuous\n- `response`: Predicted survival time\n:::\n\nFor the cox model, `crank = lp` (the higher, the more risk):\n\n::: {.cell}\n\n```{.r .cell-code}\np$lp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           1            2            3            4            5            6 \n-0.700201337  1.028226970 -0.375816571  0.816563800 -0.185087141  0.411187485 \n           7            8            9           10           11           12 \n 0.283576898  0.352202395  0.464643104  1.556489894  0.380432009  0.953430081 \n          13           14           15           16           17           18 \n 0.613978574  0.168618620  0.440813175  0.603358317 -0.955983866 -0.183689510 \n          19           20           21           22           23           24 \n 0.043210567  0.049214390 -0.790112114  0.474345598  0.158416163  0.618235104 \n          25           26           27           28           29           30 \n-0.458227141 -0.688933251  0.673196757  0.881672255 -0.241967726  0.550904241 \n          31           32           33 \n 0.605988685  0.890416067 -0.004345193 \n```\n:::\n:::\n\n\nSurvival prediction is a 2D `matrix` essentially, with dimensions: observations x time points:\n\n::: {.cell}\n\n```{.r .cell-code}\np$data$distr[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          5        11        12        13        26\n1 0.9979931 0.9959835 0.9939475 0.9918779 0.9897800\n2 0.9887499 0.9775894 0.9663876 0.9551100 0.9437888\n3 0.9972252 0.9944488 0.9916380 0.9887832 0.9858917\n4 0.9908862 0.9818254 0.9727112 0.9635150 0.9542623\n5 0.9966431 0.9932862 0.9898897 0.9864422 0.9829525\n```\n:::\n:::\n\n\nUsers should use the [distr6](https://github.com/xoopR/distr6) interface to access this prediction type, which allows us to retrieve survival probabilities (or hazards) for any time point of interest:\n\n::: {.cell}\n\n```{.r .cell-code}\n# first 4 patients in the test set, specific time points:\np$distr[1:4]$survival(c(100, 500, 1200))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]        [,2]      [,3]       [,4]\n100  0.9602155 0.795617321 0.9453939 0.83108638\n500  0.6489208 0.087559224 0.5498287 0.13933856\n1200 0.4036618 0.006041878 0.2851358 0.01601186\n```\n:::\n:::\n\n\n### Model evaluation {-}\n\n:::{.callout-tip title=\"Model validation\"}\nValidation of a survival model can be done by assessing:\n\n1. **Discrimination**: the ability of the model to distinguish between low and high risk patients\n2. **Calibration**: the agreement between the observed and predicted survival probabilities\n3. **Overall performance**: the distance between the observed and predicted survival probabilities\n:::\n\nMany measures included in `mlr3proba`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_measures$keys(pattern = \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"surv.brier\"         \"surv.calib_alpha\"   \"surv.calib_beta\"   \n [4] \"surv.chambless_auc\" \"surv.cindex\"        \"surv.dcalib\"       \n [7] \"surv.graf\"          \"surv.hung_auc\"      \"surv.intlogloss\"   \n[10] \"surv.logloss\"       \"surv.mae\"           \"surv.mse\"          \n[13] \"surv.nagelk_r2\"     \"surv.oquigley_r2\"   \"surv.rcll\"         \n[16] \"surv.rmse\"          \"surv.schmid\"        \"surv.song_auc\"     \n[19] \"surv.song_tnr\"      \"surv.song_tpr\"      \"surv.uno_auc\"      \n[22] \"surv.uno_tnr\"       \"surv.uno_tpr\"       \"surv.xu_r2\"        \n```\n:::\n:::\n\n\nMost commonly used metrics are for assessing discrimination, such as **Harrell's C-index**, **Uno's C-index** and the **(time-dependent) AUC**:\n\n::: {.cell}\n\n```{.r .cell-code}\nharrell_c = msr(\"surv.cindex\", id = \"surv.cindex.harrell\")\nuno_c = msr(\"surv.cindex\", weight_meth = \"G2\")\nuno_auci = msr(\"surv.uno_auc\", integrated = TRUE) # across all times in the test set\nuno_auc = msr(\"surv.uno_auc\", integrated = FALSE, times = 10) # at a specific time-point of interest\n\nharrell_c\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvCindex:surv.cindex.harrell>\n* Packages: mlr3, mlr3proba\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: weight_meth=I, tiex=0.5, eps=0.001\n* Properties: -\n* Predict type: crank\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\nuno_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvUnoAUC:surv.uno_auc>\n* Packages: mlr3, mlr3proba, survAUC\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: integrated=FALSE, times=10\n* Properties: requires_task, requires_train_set\n* Predict type: lp\n* Return type: Score\n```\n:::\n:::\n\n\n:::{.callout-note}\n- Not all measures are applicable to all models - **prediction type** matters!\n- Most discrimination metrics use the `crank` or `lp` prediction\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$score(harrell_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.cindex.harrell \n          0.5282052 \n```\n:::\n\n```{.r .cell-code}\np$score(uno_c, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.cindex \n  0.5292394 \n```\n:::\n:::\n\n\nCalibration is traditionally performed graphically via calibration plots:\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(p, type = \"calib\", task = task, row_ids = part$test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nBut there exists also calibration metrics, e.g. **D-Calibration**:\n\n::: {.cell}\n\n```{.r .cell-code}\ndcal = msr(\"surv.dcalib\")\ndcal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvDCalibration:surv.dcalib>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: B=10, chisq=FALSE, truncate=Inf\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(dcal)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.dcalib \n   3.918884 \n```\n:::\n:::\n\n\nOverall survival prediction performance can be assessed by scoring rules such as the **Integrated Survival Brier Score** (ISBS) and the **Right-censored Log-Loss** (RCLL) among others:\n\n::: {.cell}\n\n```{.r .cell-code}\nrcll = msr(\"surv.rcll\")\nrcll\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvRCLL:surv.rcll>\n* Packages: mlr3, mlr3proba, distr6\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: eps=1e-15, se=FALSE, ERV=FALSE, na.rm=TRUE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(rcll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.rcll \n 22.55022 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nibrier = msr(\"surv.brier\", proper = TRUE)\nibrier\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvGraf:surv.graf>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: integrated=TRUE, method=2, se=FALSE, proper=TRUE,\n  eps=0.001, ERV=FALSE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(ibrier, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.graf \n0.1881289 \n```\n:::\n:::\n\n\n### Using ML survival models {-}\n\nMention from `mlr3extralearners`: cv.glmnet, aorsf, ranger, CoxBoost\n\n## Benchmark example: GEX + clinical data {-}\n\n- From the tutorial (https://ocbe-uio.github.io/survomics/survomics.html#workflow)\n- data => https://github.com/ocbe-uio/survomics/blob/main/data.rds\n- Benchmark + posthoc analysis of results with `mlr3benchmark`\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}