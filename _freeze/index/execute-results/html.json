{
  "hash": "3572420ad5f1c88418aaa74bc56ff0f9",
  "result": {
    "markdown": "---\ntitle: \"Intro to Machine Learning for Survival Analysis with mlr3\"\nauthor: \"[John Zobolas](https://github.com/bblodfon), [Lukas Burk](https://lukasburk.de/)\"\ndate: last-modified\ndescription: \"Tutorial for the useR! 2024 conference in Salzburg, Austria (8-11 July)\"\nformat:\n  html:\n    date: last-modified\n    code-block-bg: true\n    code-copy: true\n    code-fold: show\n    code-overflow: wrap\n    code-block-border-left: true\n    toc: true\n    toc-location: left\n    html-math-method: katex\n    page-layout: full\nexecute:\n  freeze: true\n---\n\n\n\n\n## `mlr3`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand how `{mlr3}` is structured\n- Access `learner`s and (built-in) `task`s\n:::\n\nTo get started, we load `{mlr3verse}`, which will load various packages from the `{mlr3}` ecosystem:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\n`{mlr3}` ships with wrappers for many commonly used machine learning algorithms (\"learners\").  \nWe can access the list of available learners using the `mlr_learners` dictionary:\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(mlr_learners$keys(), 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"classif.multinom\"    \"regr.kknn\"           \"surv.ctree\"         \n [4] \"classif.featureless\" \"regr.fnn\"            \"surv.cforest\"       \n [7] \"classif.liblinear\"   \"classif.catboost\"    \"classif.ctree\"      \n[10] \"surv.mboost\"        \n```\n:::\n:::\n\n\nOne example:\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn(\"classif.ranger\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerClassifRanger:classif.ranger>\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n:::\n:::\n\n\n:::{.callout-note}\nUse `lrn(\"classif.ranger\")$help()` to view the help page, with links to documentation for parameters and other information about the wrapped learner.\n:::\n\nBuilt-in tasks can be accessed using the `mlr_tasks` dictionary:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_tasks)[, list(key, label, task_type, nrow, ncol, properties)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKey: <key>\n              key                     label task_type  nrow  ncol properties\n           <char>                    <char>    <char> <int> <int>     <list>\n1:   ames_housing          Ames House Sales      regr  2930    82           \n2:   bike_sharing       Bike Sharing Demand      regr 17379    14           \n3: boston_housing     Boston Housing Prices      regr   506    18           \n4:  breast_cancer   Wisconsin Breast Cancer   classif   683    10   twoclass\n5:  german_credit             German Credit   classif  1000    21   twoclass\n6:           ilpd Indian Liver Patient Data   classif   583    11   twoclass\n```\n:::\n:::\n\n\nOne example:\n\n::: {.cell}\n\n```{.r .cell-code}\ntsk(\"penguins_simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassif:penguins> (333 x 11): Simplified Palmer Penguins\n* Target: species\n* Properties: multiclass\n* Features (10):\n  - dbl (7): bill_depth, bill_length, island.Biscoe, island.Dream,\n    island.Torgersen, sex.female, sex.male\n  - int (3): body_mass, flipper_length, year\n```\n:::\n:::\n\n\n:::{.callout-note}\nTasks encapsulate a data source (typically a `data.table`) and additional information regarding which variables are considered features and target.\nTasks can also specify additional properties such as stratification, which we will see later.\n:::\n\n## Example: Train-Predict-Evaluate {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Perform a simple train-predict-evaluate step\n- Use built-in classification `task` and `learner`\n:::\n\nThe below code snippet trains a random forest model on the `penguins_simple` task (a simplified version of the `palmerpenguins` dataset, but without missing values) and evaluates the model's performance using the classification error metric:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = tsk(\"penguins_simple\")\nlearner = lrn(\"classif.ranger\", num.trees = 10)\n\npart = partition(task, ratio = 0.8) # by default stratifies on the target column\n\nlearner$train(task, row_ids = part$train)\npreds = learner$predict(task, row_ids = part$test)\npreds$score(msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n         0 \n```\n:::\n:::\n\n\n## `mlr3proba`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand survival tasks and how they differ from regression/classification\n- Know how to conduct basic modeling with `{mlr3proba}`\n- Prediction types\n- Survival measures\n:::\n\n`{mlr3proba}` extends `{mlr3}` with survival analysis capabilities.\n\n:::{.callout-important}\nAs of now, `{mlr3proba}` is not on CRAN, but you can install it [from GitHub](https://github.com/mlr-org/mlr3proba/?tab=readme-ov-file#installation) or [r-universe](https://mlr-org.r-universe.dev/mlr3proba).\nMore info is also available on the respective [mlr3 book chapter](https://mlr3book.mlr-org.com/chapters/chapter13/beyond_regression_and_classification.html#sec-survival).\n:::\n\n### Survival Tasks {-}\n\nWe'll start by using the built-in `lung` dataset, which is a survival task with $7$ features and $168$ observations:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3proba)\ntask = tsk(\"lung\")\n\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskSurv:lung> (168 x 9): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (7):\n  - int (6): age, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - fct (1): sex\n```\n:::\n:::\n\n\n[See online reference](https://mlr3proba.mlr-org.com/reference/TaskSurv.html#methods) to useful methods offered by the main `TaskSurv` class.\nSome examples:\n\nTarget `Surv` object from `{survival}` (`+` denotes censored observation):\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(task$truth())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  455   210  1022+  310   361   218 \n```\n:::\n:::\n\n\nProportion of censored observations:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$cens_prop()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2797619\n```\n:::\n:::\n\n\nDoes the data satisfy the **proportional hazards** assumption? Get the p-value from the Grambsch-Therneau test:\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$prop_haz() # barely, p > 0.05 => PH\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0608371\n```\n:::\n:::\n\n\nUsing the `autoplot()` function from `{ggplot2}`, we get the Kaplan-Meier curve:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nautoplot(task) +\n  labs(title = \"Lung dataset: Kaplan-Meier curve\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nTasks shipped with `{mlr3proba}`:\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(mlr_tasks)[task_type == \"surv\", list(key, label, nrow, ncol)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKey: <key>\n             key                       label  nrow  ncol\n          <char>                      <char> <int> <int>\n 1:         actg                    ACTG 320  1151    13\n 2:         gbcs        German Breast Cancer   686    10\n 3:         gbsg        German Breast Cancer   686    10\n 4:        grace                  GRACE 1000  1000     8\n 5:         lung                 Lung Cancer   168     9\n 6:         mgus                        MGUS   176     9\n 7:          pbc Primary Biliary Cholangitis   276    19\n 8:         rats                        Rats   300     5\n 9: unemployment       Unemployment Duration  3343     6\n10:      veteran                     Veteran   137     8\n11:         whas      Worcester Heart Attack   481    11\n```\n:::\n:::\n\n\n:::{.callout-note}\n- Use [as_task_surv()](https://mlr3proba.mlr-org.com/reference/as_task_surv.html) to convert your own datasets to a `TaskSurv` object\n- Try `tsk(\"lung\")$help()` to get more info about the dataset and pre-processing applied\n:::\n\n### CoxPH learner {-}\n\nThe classical Cox Proportional Hazards model:\n\n::: {.cell}\n\n```{.r .cell-code}\ncox = lrn(\"surv.coxph\")\ncox\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<LearnerSurvCoxPH:surv.coxph>: Cox Proportional Hazards\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  [crank], distr, lp\n* Feature Types: logical, integer, numeric, factor\n* Properties: weights\n```\n:::\n:::\n\n\nTrain the cox model and access the fit object from the `{survival}` package:\n\n::: {.cell}\n\n```{.r .cell-code}\npart = partition(task, ratio = 0.8) # by default, stratification is on `status` variable\ncox$train(task, row_ids = part$train)\n\ncox$model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nsurvival::coxph(formula = task$formula(), data = task$data(), \n    x = TRUE)\n\n                coef  exp(coef)   se(coef)      z        p\nage        1.289e-02  1.013e+00  1.259e-02  1.024 0.305800\nmeal.cal  -8.302e-05  9.999e-01  2.869e-04 -0.289 0.772319\npat.karno -7.476e-03  9.926e-01  9.091e-03 -0.822 0.410844\nph.ecog    9.047e-01  2.471e+00  2.615e-01  3.460 0.000539\nph.karno   2.841e-02  1.029e+00  1.256e-02  2.261 0.023754\nsexm       7.011e-01  2.016e+00  2.251e-01  3.114 0.001843\nwt.loss   -1.258e-02  9.875e-01  8.715e-03 -1.444 0.148728\n\nLikelihood ratio test=26.97  on 7 df, p=0.0003374\nn= 135, number of events= 97 \n```\n:::\n:::\n\n\n### Prediction types {-}\n\nLet's predict using the trained cox model on the test set (output is a [PredictionSurv](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) object):\n\n::: {.cell}\n\n```{.r .cell-code}\np = cox$predict(task, row_ids = part$test)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionSurv> for 33 observations:\n    row_ids time status       crank          lp     distr\n          1  455   TRUE -0.02981212 -0.02981212 <list[1]>\n          6  218   TRUE  0.20870613  0.20870613 <list[1]>\n         10  613   TRUE  1.08385929  1.08385929 <list[1]>\n---                                                      \n        154  235  FALSE -0.25508919 -0.25508919 <list[1]>\n        162  175  FALSE -0.99021501 -0.99021501 <list[1]>\n        163  197  FALSE  0.71869698  0.71869698 <list[1]>\n```\n:::\n:::\n\n\n:::{.callout-tip title=\"Prediction types in mlr3proba\"}\n- `crank`: Continuous risk ranking\n- `lp`: Linear predictor calculated as $\\hat\\beta * X_{test}$\n- `distr`: Predicted survival distribution, either discrete or continuous\n- `response`: Predicted survival time\n:::\n\nFor the cox model, `crank = lp` (the higher, the more risk):\n\n::: {.cell}\n\n```{.r .cell-code}\np$lp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          1           2           3           4           5           6 \n-0.02981212  0.20870613  1.08385929  0.64412898  1.95694166  1.29258294 \n          7           8           9          10          11          12 \n 0.98118477  0.50306284  0.28943104  0.01861849  0.17463572 -0.16547567 \n         13          14          15          16          17          18 \n 0.05779670  0.69083172  0.88189677  0.29579355  0.96685391  1.18925249 \n         19          20          21          22          23          24 \n 1.57195467  1.07787218  1.01452642  0.42097551  1.06133443  1.10591812 \n         25          26          27          28          29          30 \n 0.40184129  0.90670656 -0.58224140  0.79403675  0.22297187  0.32272039 \n         31          32          33 \n-0.25508919 -0.99021501  0.71869698 \n```\n:::\n:::\n\n\nSurvival prediction is a 2D `matrix` essentially, with dimensions: observations x time points:\n\n::: {.cell}\n\n```{.r .cell-code}\np$data$distr[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          5        11        12        13        15\n1 0.9960952 0.9921929 0.9882408 0.9842226 0.9801466\n2 0.9950460 0.9901004 0.9850969 0.9800154 0.9748665\n3 0.9881552 0.9764127 0.9646160 0.9527207 0.9407553\n4 0.9923533 0.9847403 0.9770594 0.9692804 0.9614206\n5 0.9718741 0.9444511 0.9173608 0.8905079 0.8639642\n```\n:::\n:::\n\n\nUsers should use the [distr6](https://github.com/xoopR/distr6) interface to access this prediction type, which allows us to retrieve survival probabilities (or hazards) for any time point of interest:\n\n::: {.cell}\n\n```{.r .cell-code}\n# first 4 patients in the test set, specific time points:\np$distr[1:4]$survival(c(100, 500, 1200))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]       [,2]        [,3]       [,4]\n100  0.9014317 0.87658337 0.729032803 0.81579356\n500  0.4645821 0.37790283 0.096835009 0.22222443\n1200 0.1600068 0.09766965 0.003768671 0.02745085\n```\n:::\n:::\n\n\n### Model evaluation {-}\n\n:::{.callout-tip title=\"Model validation\"}\nValidation of a survival model can be done by assessing:\n\n1. **Discrimination**: the ability of the model to distinguish between low and high risk patients\n2. **Calibration**: the agreement between the observed and predicted survival probabilities\n3. **Overall performance**: the distance between the observed and predicted survival probabilities\n:::\n\nMany measures included in `mlr3proba`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_measures$keys(pattern = \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"surv.brier\"         \"surv.calib_alpha\"   \"surv.calib_beta\"   \n [4] \"surv.chambless_auc\" \"surv.cindex\"        \"surv.dcalib\"       \n [7] \"surv.graf\"          \"surv.hung_auc\"      \"surv.intlogloss\"   \n[10] \"surv.logloss\"       \"surv.mae\"           \"surv.mse\"          \n[13] \"surv.nagelk_r2\"     \"surv.oquigley_r2\"   \"surv.rcll\"         \n[16] \"surv.rmse\"          \"surv.schmid\"        \"surv.song_auc\"     \n[19] \"surv.song_tnr\"      \"surv.song_tpr\"      \"surv.uno_auc\"      \n[22] \"surv.uno_tnr\"       \"surv.uno_tpr\"       \"surv.xu_r2\"        \n```\n:::\n:::\n\n\nMost commonly used metrics are for assessing discrimination, such as **Harrell's C-index**, **Uno's C-index** and the **(time-dependent) AUC**:\n\n::: {.cell}\n\n```{.r .cell-code}\nharrell_c = msr(\"surv.cindex\", id = \"surv.cindex.harrell\")\nuno_c = msr(\"surv.cindex\", weight_meth = \"G2\")\nuno_auci = msr(\"surv.uno_auc\", integrated = TRUE) # across all times in the test set\nuno_auc = msr(\"surv.uno_auc\", integrated = FALSE, times = 10) # at a specific time-point of interest\n\nharrell_c\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvCindex:surv.cindex.harrell>\n* Packages: mlr3, mlr3proba\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: weight_meth=I, tiex=0.5, eps=0.001\n* Properties: -\n* Predict type: crank\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\nuno_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvUnoAUC:surv.uno_auc>\n* Packages: mlr3, mlr3proba, survAUC\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: integrated=FALSE, times=10\n* Properties: requires_task, requires_train_set\n* Predict type: lp\n* Return type: Score\n```\n:::\n:::\n\n\n:::{.callout-note}\n- Not all measures are applicable to all models - **prediction type** matters!\n- Most discrimination metrics use the `crank` or `lp` prediction\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$score(harrell_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.cindex.harrell \n          0.6458333 \n```\n:::\n\n```{.r .cell-code}\np$score(uno_c, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.cindex \n  0.5906947 \n```\n:::\n:::\n\n\nCalibration is traditionally performed graphically via calibration plots:\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(p, type = \"calib\", task = task, row_ids = part$test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nBut there exists also calibration metrics, e.g. **D-Calibration**:\n\n::: {.cell}\n\n```{.r .cell-code}\ndcal = msr(\"surv.dcalib\")\ndcal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvDCalibration:surv.dcalib>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: B=10, chisq=FALSE, truncate=Inf\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(dcal)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.dcalib \n   7.117245 \n```\n:::\n:::\n\n\nOverall survival prediction performance can be assessed by scoring rules such as the **Integrated Survival Brier Score** (ISBS) and the **Right-censored Log-Loss** (RCLL) among others:\n\n::: {.cell}\n\n```{.r .cell-code}\nrcll = msr(\"surv.rcll\")\nrcll\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvRCLL:surv.rcll>\n* Packages: mlr3, mlr3proba, distr6\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: eps=1e-15, se=FALSE, ERV=FALSE, na.rm=TRUE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(rcll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.rcll \n 22.50585 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nibrier = msr(\"surv.brier\", proper = TRUE)\nibrier\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvGraf:surv.graf>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: integrated=TRUE, method=2, se=FALSE, proper=TRUE,\n  eps=0.001, ERV=FALSE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\np$score(ibrier, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsurv.graf \n0.1646881 \n```\n:::\n:::\n\n\n### Using ML survival models {-}\n\nMention from `mlr3extralearners`: cv.glmnet, aorsf, ranger, CoxBoost\n\n## Benchmark example: GEX + clinical data {-}\n\n- From the tutorial (https://ocbe-uio.github.io/survomics/survomics.html#workflow)\n- data => https://github.com/ocbe-uio/survomics/blob/main/data.rds\n- Benchmark + posthoc analysis of results with `mlr3benchmark`\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}