{
  "hash": "95cfab95b18e5cb6bf5abbd424ad07ab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intro to Machine Learning for Survival Analysis with mlr3\"\nauthor: \"[John Zobolas](https://github.com/bblodfon), [Lukas Burk](https://lukasburk.de/)\"\ndate: last-modified\ndescription: \"Tutorial for the useR! 2024 conference in Salzburg, Austria (8-11 July)\"\nformat:\n  html:\n    date: last-modified\n    code-block-bg: true\n    code-copy: true\n    code-fold: show\n    code-overflow: wrap\n    code-block-border-left: true\n    toc: true\n    toc-location: left\n    html-math-method: katex\n    page-layout: full\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n\n## `mlr3`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand how `{mlr3}` is structured\n- Access `learner`s and (built-in) `task`s\n:::\n\nTo get started, we load `{mlr3verse}`, which will load various packages from the `{mlr3}` ecosystem:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse)\n```\n:::\n\n\n\n\n`{mlr3}` ships with wrappers for many commonly used machine learning algorithms (\"learners\").  \nWe can access the list of available learners using the `mlr_learners` dictionary:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(mlr_learners$keys(), 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"classif.lightgbm\"         \"classif.imbalanced_rfsrc\"\n [3] \"clust.hdbscan\"            \"surv.gamboost\"           \n [5] \"regr.rfsrc\"               \"classif.qda\"             \n [7] \"classif.glmer\"            \"surv.cv_glmnet\"          \n [9] \"regr.smo_reg\"             \"regr.ranger\"             \n```\n\n\n:::\n:::\n\n\n\n\nOne example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn(\"classif.ranger\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<LearnerClassifRanger:classif.ranger>: Random Forest\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3learners, ranger\n* Predict Types:  [response], prob\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: hotstart_backward, importance, multiclass, oob_error,\n  twoclass, weights\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nUse `lrn(\"classif.ranger\")$help()` to view the help page, with links to documentation for parameters and other information about the wrapped learner.\n:::\n\nBuilt-in tasks can be accessed using the `mlr_tasks` dictionary:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(as.data.table(mlr_tasks)[, list(key, label, task_type, nrow, ncol, properties)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <key>\n              key                     label task_type  nrow  ncol properties\n           <char>                    <char>    <char> <int> <int>     <list>\n1:   ames_housing          Ames House Sales      regr  2930    82           \n2:   bike_sharing       Bike Sharing Demand      regr 17379    14           \n3: boston_housing     Boston Housing Prices      regr   506    18           \n4:  breast_cancer   Wisconsin Breast Cancer   classif   683    10   twoclass\n5:  german_credit             German Credit   classif  1000    21   twoclass\n6:           ilpd Indian Liver Patient Data   classif   583    11   twoclass\n```\n\n\n:::\n:::\n\n\n\n\nOne example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntsk(\"penguins_simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskClassif:penguins> (333 x 11): Simplified Palmer Penguins\n* Target: species\n* Properties: multiclass\n* Features (10):\n  - dbl (7): bill_depth, bill_length, island.Biscoe, island.Dream,\n    island.Torgersen, sex.female, sex.male\n  - int (3): body_mass, flipper_length, year\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nTasks encapsulate a data source (typically a `data.table`) and additional information regarding which variables are considered features and target.\nTasks can also specify additional properties such as stratification, which we will see later.\n:::\n\n## Example: Train-Predict-Evaluate {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Perform a simple train-predict-evaluate step\n- Use built-in classification `task` and `learner`\n:::\n\nThe below code snippet trains a random forest model on the `penguins_simple` task (a simplified version of the `palmerpenguins` dataset, but without missing values) and evaluates the model's performance using the classification error metric:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = tsk(\"penguins_simple\")\nlearner = lrn(\"classif.ranger\", num.trees = 10)\n\npart = partition(task, ratio = 0.8) # by default stratifies on the target column\n\nlearner$train(task, row_ids = part$train)\npreds = learner$predict(task, row_ids = part$test)\npreds$score(msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclassif.ce \n0.01492537 \n```\n\n\n:::\n:::\n\n\n\n\n## `mlr3proba`: Basics {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Understand survival tasks and how they differ from regression/classification\n- Know how to conduct basic modeling with `{mlr3proba}`\n- Prediction types\n- Survival measures\n:::\n\n`{mlr3proba}` extends `{mlr3}` with survival analysis capabilities.\n\n:::{.callout-important}\nAs of now, `{mlr3proba}` is not on CRAN, but you can install it [from GitHub](https://github.com/mlr-org/mlr3proba/?tab=readme-ov-file#installation) or [r-universe](https://mlr-org.r-universe.dev/mlr3proba).\nMore info is also available on the respective [mlr3 book chapter](https://mlr3book.mlr-org.com/chapters/chapter13/beyond_regression_and_classification.html#sec-survival).\n:::\n\n### Survival Tasks {-}\n\nWe'll start by using the built-in `lung` dataset, which is a survival task with $7$ features and $168$ observations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3proba)\ntask = tsk(\"lung\")\n\ntask\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<TaskSurv:lung> (168 x 9): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (7):\n  - int (6): age, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - fct (1): sex\n```\n\n\n:::\n:::\n\n\n\n\n[See online reference](https://mlr3proba.mlr-org.com/reference/TaskSurv.html#methods) to useful methods offered by the main `TaskSurv` class.\nSome examples:\n\nTarget `Surv` object from `{survival}` (`+` denotes censored observation):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(task$truth())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  455   210  1022+  310   361   218 \n```\n\n\n:::\n:::\n\n\n\n\nProportion of censored observations:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$cens_prop()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2797619\n```\n\n\n:::\n:::\n\n\n\n\nDoes the data satisfy the **proportional hazards** assumption? Get the p-value from the Grambsch-Therneau test (see `?survival::cox.zph`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask$prop_haz() # barely, p > 0.05 => PH\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0608371\n```\n\n\n:::\n:::\n\n\n\n\nUsing the `autoplot()` function from `{ggplot2}`, we get the Kaplan-Meier curve:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nautoplot(task) +\n  labs(title = \"Lung dataset: Kaplan-Meier curve\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/km-curve-1.png){width=672}\n:::\n:::\n\n\n\n\nTasks shipped with `{mlr3proba}`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.data.table(mlr_tasks)[task_type == \"surv\", list(key, label, nrow, ncol)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <key>\n             key                       label  nrow  ncol\n          <char>                      <char> <int> <int>\n 1:         actg                    ACTG 320  1151    13\n 2:         gbcs        German Breast Cancer   686    10\n 3:         gbsg        German Breast Cancer   686    10\n 4:        grace                  GRACE 1000  1000     8\n 5:         lung                 Lung Cancer   168     9\n 6:         mgus                        MGUS   176     9\n 7:          pbc Primary Biliary Cholangitis   276    19\n 8:         rats                        Rats   300     5\n 9: unemployment       Unemployment Duration  3343     6\n10:      veteran                     Veteran   137     8\n11:         whas      Worcester Heart Attack   481    11\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\n- Use [as_task_surv()](https://mlr3proba.mlr-org.com/reference/as_task_surv.html) to convert your own datasets to a `TaskSurv` object\n- Try `tsk(\"lung\")$help()` to get more info about the dataset and pre-processing applied\n:::\n\n### CoxPH learner {-}\n\nThe classical Cox Proportional Hazards model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncox = lrn(\"surv.coxph\")\ncox\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<LearnerSurvCoxPH:surv.coxph>: Cox Proportional Hazards\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  [crank], distr, lp\n* Feature Types: logical, integer, numeric, factor\n* Properties: weights\n```\n\n\n:::\n:::\n\n\n\n\nTrain the cox model and access the fit object from the `{survival}` package:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\npart = partition(task, ratio = 0.8) # by default, stratification is on `status` variable\ncox$train(task, row_ids = part$train)\n\ncox$model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nsurvival::coxph(formula = task$formula(), data = task$data(), \n    x = TRUE)\n\n                coef  exp(coef)   se(coef)      z      p\nage        1.341e-02  1.013e+00  1.258e-02  1.066 0.2864\nmeal.cal  -5.007e-05  9.999e-01  2.903e-04 -0.172 0.8631\npat.karno -2.142e-02  9.788e-01  9.055e-03 -2.366 0.0180\nph.ecog    5.936e-01  1.811e+00  2.500e-01  2.375 0.0176\nph.karno   2.541e-02  1.026e+00  1.263e-02  2.011 0.0443\nsexm       4.510e-01  1.570e+00  2.298e-01  1.962 0.0497\nwt.loss   -1.500e-02  9.851e-01  8.395e-03 -1.787 0.0739\n\nLikelihood ratio test=23.36  on 7 df, p=0.001475\nn= 135, number of events= 97 \n```\n\n\n:::\n:::\n\n\n\n\nVisual output of the model, using the latest version from Github of `{mlr3viz}`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(cox)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/cox-model-viz-1.png){width=672}\n:::\n:::\n\n\n\n\n### Prediction types {-}\n\nLet's predict using the trained cox model on the test set (output is a [PredictionSurv](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) object):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np = cox$predict(task, row_ids = part$test)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<PredictionSurv> for 33 observations:\n    row_ids time status       crank          lp     distr\n          1  455   TRUE -0.16022736 -0.16022736 <list[1]>\n          8  170   TRUE  0.07608537  0.07608537 <list[1]>\n         15  371   TRUE -0.46601841 -0.46601841 <list[1]>\n---                                                      \n        165  191  FALSE -0.30526841 -0.30526841 <list[1]>\n        166  105  FALSE  0.49632782  0.49632782 <list[1]>\n        168  177  FALSE -0.17234336 -0.17234336 <list[1]>\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip title=\"Prediction types in mlr3proba\"}\n- `crank`: Continuous risk ranking\n- `lp`: Linear predictor calculated as $\\hat\\beta * X_{test}$\n- `distr`: Predicted survival distribution, either discrete or continuous\n- `response`: Predicted survival time\n:::\n\nFor the cox model, `crank = lp` (the higher, the more risk):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$lp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           1            2            3            4            5            6 \n-0.160227364  0.076085366 -0.466018411  0.293380270  1.179147761  0.523244848 \n           7            8            9           10           11           12 \n 0.391564618 -0.029833700 -0.149489235 -0.262762070  0.076021387  0.279388934 \n          13           14           15           16           17           18 \n 0.889995280  0.859467193  1.030472975  0.277533930 -0.057165655  0.362416853 \n          19           20           21           22           23           24 \n-0.037670338 -0.295071061 -0.419840184  0.793214751  0.823500785  0.977222024 \n          25           26           27           28           29           30 \n-0.046252611  0.021227170 -0.093541236 -0.158438686  1.615114453  0.003701068 \n          31           32           33 \n-0.305268413  0.496327822 -0.172343361 \n```\n\n\n:::\n:::\n\n\n\n\nSurvival prediction is a 2D `matrix` essentially, with dimensions: *observations* x *time points*:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$data$distr[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          5        11        12        13        15\n1 0.9959775 0.9919519 0.9879072 0.9837970 0.9796477\n2 0.9949079 0.9898175 0.9847084 0.9795222 0.9742926\n3 0.9970357 0.9940659 0.9910789 0.9880402 0.9849691\n4 0.9936759 0.9873617 0.9810323 0.9746156 0.9681535\n5 0.9847342 0.9696296 0.9546262 0.9395560 0.9245212\n```\n\n\n:::\n:::\n\n\n\n\nUsers should use the [distr6](https://github.com/xoopR/distr6) interface to access this prediction type, which allows us to retrieve survival probabilities (or hazards) for any time point of interest:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first 4 patients in the test set, specific time points:\np$distr[1:4]$survival(c(100, 500, 1200))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]      [,3]       [,4]\n100  0.9184997 0.8979186 0.9393041 0.87475634\n500  0.4589611 0.3729197 0.5634874 0.29352281\n1200 0.1684876 0.1048078 0.2693617 0.06062239\n```\n\n\n:::\n:::\n\n\n\n\nVisualization of predicted survival curves for $3$ test patients:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 = p$clone()$filter(row_ids = c(1,24,40))\nautoplot(p2, type = \"preds\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pred-curves-1.png){width=672}\n:::\n:::\n\n\n\n\n### Model evaluation {-}\n\n:::{.callout-tip title=\"Model validation\"}\nValidation of a survival model can be done by assessing:\n\n1. **Discrimination**: the ability of the model to distinguish between low and high risk patients\n2. **Calibration**: the agreement between the observed and predicted survival probabilities\n3. **Overall performance**: the distance between the observed and predicted survival probabilities\n:::\n\nMany measures included in `mlr3proba`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_measures$keys(pattern = \"surv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"surv.brier\"         \"surv.calib_alpha\"   \"surv.calib_beta\"   \n [4] \"surv.chambless_auc\" \"surv.cindex\"        \"surv.dcalib\"       \n [7] \"surv.graf\"          \"surv.hung_auc\"      \"surv.intlogloss\"   \n[10] \"surv.logloss\"       \"surv.mae\"           \"surv.mse\"          \n[13] \"surv.nagelk_r2\"     \"surv.oquigley_r2\"   \"surv.rcll\"         \n[16] \"surv.rmse\"          \"surv.schmid\"        \"surv.song_auc\"     \n[19] \"surv.song_tnr\"      \"surv.song_tpr\"      \"surv.uno_auc\"      \n[22] \"surv.uno_tnr\"       \"surv.uno_tpr\"       \"surv.xu_r2\"        \n```\n\n\n:::\n:::\n\n\n\n\nMost commonly used metrics are for assessing discrimination, such as **Harrell's C-index**, **Uno's C-index** and the **(time-dependent) AUC**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nharrell_c = msr(\"surv.cindex\", id = \"surv.cindex.harrell\")\nuno_c = msr(\"surv.cindex\", weight_meth = \"G2\", id = \"surv.cindex.uno\")\nuno_auci = msr(\"surv.uno_auc\", integrated = TRUE) # across all times in the test set\nuno_auc = msr(\"surv.uno_auc\", integrated = FALSE, times = 10) # at a specific time-point of interest\n\nharrell_c\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvCindex:surv.cindex.harrell>\n* Packages: mlr3, mlr3proba\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: weight_meth=I, tiex=0.5, eps=0.001\n* Properties: -\n* Predict type: crank\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\nuno_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvUnoAUC:surv.uno_auc>\n* Packages: mlr3, mlr3proba, survAUC\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: integrated=FALSE, times=10\n* Properties: requires_task, requires_train_set\n* Predict type: lp\n* Return type: Score\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\n- Not all measures are applicable to all models - **prediction type** matters!\n- Most discrimination metrics use the `crank` or `lp` prediction\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np$score(harrell_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.cindex.harrell \n          0.6336898 \n```\n\n\n:::\n\n```{.r .cell-code}\np$score(uno_c, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.cindex.uno \n      0.5907828 \n```\n\n\n:::\n:::\n\n\n\n\nCalibration is traditionally performed graphically via calibration plots:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(p, type = \"calib\", task = task, row_ids = part$test)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/calib-plot-1.png){width=672}\n:::\n:::\n\n\n\n\nBut there exists also calibration metrics, e.g. **D-Calibration**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcal = msr(\"surv.dcalib\")\ndcal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvDCalibration:surv.dcalib>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: B=10, chisq=FALSE, truncate=Inf\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(dcal)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.dcalib \n   8.320423 \n```\n\n\n:::\n:::\n\n\n\n\nOverall survival prediction performance can be assessed by scoring rules such as the **Integrated Survival Brier Score** (ISBS) and the **Right-censored Log-Loss** (RCLL) among others:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcll = msr(\"surv.rcll\")\nrcll\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvRCLL:surv.rcll>\n* Packages: mlr3, mlr3proba, distr6\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: eps=1e-15, se=FALSE, ERV=FALSE, na.rm=TRUE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(rcll)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.rcll \n 23.46684 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nibrier = msr(\"surv.brier\", proper = TRUE)\nibrier\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<MeasureSurvGraf:surv.graf>\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: integrated=TRUE, method=2, se=FALSE, proper=TRUE,\n  eps=0.001, ERV=FALSE\n* Properties: -\n* Predict type: distr\n* Return type: Score\n```\n\n\n:::\n\n```{.r .cell-code}\np$score(ibrier, task = task, train_set = part$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsurv.graf \n0.1591112 \n```\n\n\n:::\n:::\n\n\n\n\n## Using ML survival models on high-dimensional data {-}\n\nSo far we have used the Cox regression model, but there are many more machine learning methods available via `mlr3extralearners`!\nWe will take a look at the following:\n\n- Cox elastic net via [`glmnet`](https://glmnet.stanford.edu/articles/Coxnet.html)\n  - We will use `lrn(\"surv.cv_glmnet\")`, wich internally tunes for `lambda` using cross-validation\n- Likelihood-based boosting via [`CoxBoost`](https://github.com/binderh/CoxBoost)\n  - We will use `lrn(\"surv.cv_coxboost\", penalty = \"optimCoxBoostPenalty\")`, which also uses internal cross-validation to tune its parameters\n- Random Forests via [`ranger`](https://imbs-hl.github.io/ranger/)\n- Oblique Random Forests via [`aorsf`](https://docs.ropensci.org/aorsf/)\n\nThese learners then cover the range from penalized regression to tree ensembles and boosting.\n\nLet's take these learners for a spin on a subset of TCGA breast cancer data with gene expression and clinical features.\nWe first need to create a `TaskSurv` object from the data, which we can do by reading in the data and then using `as_task_surv()`.\nWe also add the `status` column to the stratum, which is necessary for the resampling to ensure a similar proportion of events in the resampling folds than the complete dataset.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntcga = readRDS(\"data/tcga.rds\")\n\ntask_tcga <- mlr3proba::as_task_surv(\n  x = tcga, \n  time = \"time\", event = \"status\", id = \"BRCA-TCGA\"\n)\n\n# Set stratum for resampling\ntask$set_col_roles(\"status\", add_to = \"stratum\")\n```\n:::\n\n\n\n\nWe can instantiate our learners as we've seen before --- we're sticking to mostly vanilla settings for now.  \nWe can let `glmnet` determine the optimal value for `lambda` with it's internal cross-validation method\nSimilarly, `CoxBoost` could tune itself, but we'll stick with a simple version to save some time on compute!\nFor the forests, we use 100 trees each for speed and otherwise accept the defaults.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlrn_glmnet = lrn(\"surv.cv_glmnet\", alpha = 0.5)\nlrn_coxboost = lrn(\"surv.coxboost\", penalty = 100)\nlrn_ranger = lrn(\"surv.ranger\", num.trees = 100)\nlrn_aorsf = lrn(\"surv.aorsf\", n_tree = 100)\n```\n:::\n\n\n\n\nWe can now use `resample()` to evaluate the performance of each of these learners on the task.\nTo to this, we decide on two measures: Harrell's C and the integrated brier score, and we also instantiate a resampling to use for comparison, such that we ensure all learners see the same data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasures = list(msr(\"surv.cindex\", id = \"cindex\"), msr(\"surv.brier\", id = \"ibs\"))\n\nresampling = rsmp(\"cv\", folds = 3)\nresampling$instantiate(task_tcga)\n\nrr_glmnet = resample(\n  task = task_tcga,\n  learner = lrn_glmnet,\n  resampling = resampling\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:03:38.096] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:39.335] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:40.167] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 3/3)\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_glmnet$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     task_id     learner_id resampling_id iteration cindex       ibs\n      <char>         <char>        <char>     <int>  <num>     <num>\n1: BRCA-TCGA surv.cv_glmnet            cv         1    0.5 0.1756614\n2: BRCA-TCGA surv.cv_glmnet            cv         2    0.5 0.1324771\n3: BRCA-TCGA surv.cv_glmnet            cv         3    0.5 0.2651273\nHidden columns: task, learner, resampling, prediction\n```\n\n\n:::\n:::\n\n\n\n\nWell, looks like `glmnet` out of the box does not do well on this dataset, judging by the C-index of 0.5.\nThis is what the null model achieves, after all!\n\nFeel free to play with the parameters of `glmnet` a bit more --- for example, does changing `alpha` help?\n\nWe can repeat the same procedure for the other learners:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr_coxboost = resample(\n  task = task_tcga,\n  learner = lrn_coxboost,\n  resampling = resampling\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:03:41.486] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:41.989] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:42.587] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 3/3)\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_ranger = resample(\n  task = task_tcga,\n  learner = lrn_ranger,\n  resampling = resampling\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:03:43.034] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:45.247] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:47.512] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 3/3)\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_aorsf = resample(\n  task = task_tcga,\n  learner = lrn_aorsf,\n  resampling = resampling\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:03:50.010] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:50.110] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:50.149] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 3/3)\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_coxboost$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     task_id    learner_id resampling_id iteration    cindex       ibs\n      <char>        <char>        <char>     <int>     <num>     <num>\n1: BRCA-TCGA surv.coxboost            cv         1 0.6715095 0.2181875\n2: BRCA-TCGA surv.coxboost            cv         2 0.5843462 0.1397133\n3: BRCA-TCGA surv.coxboost            cv         3 0.5756824 0.2642506\nHidden columns: task, learner, resampling, prediction\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_ranger$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     task_id  learner_id resampling_id iteration    cindex       ibs\n      <char>      <char>        <char>     <int>     <num>     <num>\n1: BRCA-TCGA surv.ranger            cv         1 0.6609037 0.2281387\n2: BRCA-TCGA surv.ranger            cv         2 0.6891946 0.1394615\n3: BRCA-TCGA surv.ranger            cv         3 0.5599183 0.2884375\nHidden columns: task, learner, resampling, prediction\n```\n\n\n:::\n\n```{.r .cell-code}\nrr_aorsf$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     task_id learner_id resampling_id iteration    cindex       ibs\n      <char>     <char>        <char>     <int>     <num>     <num>\n1: BRCA-TCGA surv.aorsf            cv         1 0.6649716 0.2139267\n2: BRCA-TCGA surv.aorsf            cv         2 0.6576733 0.1297630\n3: BRCA-TCGA surv.aorsf            cv         3 0.5644432 0.2737022\nHidden columns: task, learner, resampling, prediction\n```\n\n\n:::\n:::\n\n\n\n\nNow we have a comparison of the performance of the different learners on the task.\nWe can again aggregate these results to get a summary of the performance of each learner across all resamplings:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr_glmnet$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cindex       ibs \n0.5000000 0.1910886 \n```\n\n\n:::\n\n```{.r .cell-code}\nrr_coxboost$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cindex       ibs \n0.6105127 0.2073838 \n```\n\n\n:::\n\n```{.r .cell-code}\nrr_ranger$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cindex       ibs \n0.6366722 0.2186793 \n```\n\n\n:::\n\n```{.r .cell-code}\nrr_aorsf$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cindex       ibs \n0.6290294 0.2057973 \n```\n\n\n:::\n:::\n\n\n\n\n\nNow, for a quick example on a single dataset this approach is goon enough, but a bit cumbersome.\nWhat we essentially did here was a naive benchmarking of the learners on the task --- something `mlr3` has dedicated tools for!\n\nWe can perform the same procedure by first defining a *benchmark design* of one or more tasks and at least two learners like so:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndesign = benchmark_grid(\n  tasks = task_tcga,\n  learners = list(lrn_glmnet, lrn_ranger, lrn_aorsf, lrn_coxboost),\n  resamplings = resampling\n)\n\ndesign\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        task        learner resampling\n      <char>         <char>     <char>\n1: BRCA-TCGA surv.cv_glmnet         cv\n2: BRCA-TCGA    surv.ranger         cv\n3: BRCA-TCGA     surv.aorsf         cv\n4: BRCA-TCGA  surv.coxboost         cv\n```\n\n\n:::\n:::\n\n\n\n\nTo perform the benchmark, we use the aptly named `benchmark()` function, which will perform the necessary resampling iterations and store the results for us:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbmr = benchmark(design, store_models = TRUE, store_backends = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:03:51.492] [mlr3] Running benchmark with 12 resampling iterations\nINFO  [17:03:51.495] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:52.476] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:53.292] [mlr3] Applying learner 'surv.cv_glmnet' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:03:54.307] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:03:56.622] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:03:58.963] [mlr3] Applying learner 'surv.ranger' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:04:01.498] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:04:01.534] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:04:01.570] [mlr3] Applying learner 'surv.aorsf' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:04:01.613] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 1/3)\nINFO  [17:04:02.202] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 2/3)\nINFO  [17:04:02.629] [mlr3] Applying learner 'surv.coxboost' on task 'BRCA-TCGA' (iter 3/3)\nINFO  [17:04:03.056] [mlr3] Finished benchmark\n```\n\n\n:::\n\n```{.r .cell-code}\nbmr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<BenchmarkResult> of 12 rows with 4 resampling runs\n nr   task_id     learner_id resampling_id iters warnings errors\n  1 BRCA-TCGA surv.cv_glmnet            cv     3        0      0\n  2 BRCA-TCGA    surv.ranger            cv     3        0      0\n  3 BRCA-TCGA     surv.aorsf            cv     3        0      0\n  4 BRCA-TCGA  surv.coxboost            cv     3        0      0\n```\n\n\n:::\n:::\n\n\n\n\nWhen we `$score()` or `$aggregate()` the benchmark result, we should get the same exact scores as before because we used the instantiated resampling from earlier, meaning each elarner again saw the same data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbmr$score(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       nr   task_id     learner_id resampling_id iteration    cindex       ibs\n    <int>    <char>         <char>        <char>     <int>     <num>     <num>\n 1:     1 BRCA-TCGA surv.cv_glmnet            cv         1 0.5000000 0.1756614\n 2:     1 BRCA-TCGA surv.cv_glmnet            cv         2 0.5000000 0.1324771\n 3:     1 BRCA-TCGA surv.cv_glmnet            cv         3 0.5000000 0.2651273\n 4:     2 BRCA-TCGA    surv.ranger            cv         1 0.6834229 0.2226761\n 5:     2 BRCA-TCGA    surv.ranger            cv         2 0.6858555 0.1402617\n 6:     2 BRCA-TCGA    surv.ranger            cv         3 0.5527660 0.2897589\n 7:     3 BRCA-TCGA     surv.aorsf            cv         1 0.6579980 0.2097476\n 8:     3 BRCA-TCGA     surv.aorsf            cv         2 0.6407106 0.1320248\n 9:     3 BRCA-TCGA     surv.aorsf            cv         3 0.5804992 0.2769839\n10:     4 BRCA-TCGA  surv.coxboost            cv         1 0.6715095 0.2181875\n11:     4 BRCA-TCGA  surv.coxboost            cv         2 0.5843462 0.1397133\n12:     4 BRCA-TCGA  surv.coxboost            cv         3 0.5756824 0.2642506\nHidden columns: uhash, task, learner, resampling, prediction\n```\n\n\n:::\n\n```{.r .cell-code}\nbmr$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      nr   task_id     learner_id resampling_id iters    cindex       ibs\n   <int>    <char>         <char>        <char> <int>     <num>     <num>\n1:     1 BRCA-TCGA surv.cv_glmnet            cv     3 0.5000000 0.1910886\n2:     2 BRCA-TCGA    surv.ranger            cv     3 0.6406815 0.2175656\n3:     3 BRCA-TCGA     surv.aorsf            cv     3 0.6264026 0.2062521\n4:     4 BRCA-TCGA  surv.coxboost            cv     3 0.6105127 0.2073838\nHidden columns: resample_result\n```\n\n\n:::\n:::\n\n\n\n\nWe can also visualize the results --- see `?autoplot.BenchmarkResult` for more options:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(bmr, type = \"boxplot\", measure = msr(\"surv.brier\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bmr-box-1.png){width=672}\n:::\n:::\n\n\n\n\nFrom our quick tests, which learner now seems to have done the best?\nGiven that we used these learners more or less off the shelf without tuning, we should not put too much weight on these results, but it's a good starting point for further exploration!\n\nTuning is a complex topic and you can learn more about it in the [mlr3book chapter](https://mlr3book.mlr-org.com/chapters/chapter4/hyperparameter_optimization.html), but unfortunately we don't have time to cover it here!\n\n## Benchmarking with multiple datasets {-}\n\n:::{.callout-tip title=\"Teaching Aims\"}\n- Perform a small-scale benchmark\n- Aggregate and visualize the results\n- Perform a statistical analysis of the results\n:::\n\nA proper benchmark can take a lot of time and planning, but it can pay off to get a good overview of the performance of different learners on different tasks relevant to your field!\n\nIn this example, we'll take a number of small datasets provided by `mlr3proba` and benchmark the learners we used before on them.\nThese tasks are small enough to hopefully not spend too much time waiting for computations to finish, but we hope you get enough of an idea to feel confident to perform your own experiments!\n\nThe procedure is as follows:\n\n1. Gather tasks as a list.\n2. Gather our learners. Normally this would include deciding on tuning spaces!\n3. Define a resampling strategy.\n4. Decide on measures to use.\n\n\nFor step 1, we'll select some survival tasks from `mlr_tasks` for this benchmark:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntasks = list(\n  tsk(\"actg\"),\n  tsk(\"gbcs\"),\n  tsk(\"grace\"),\n  tsk(\"lung\"),\n  tsk(\"mgus\")\n)\n\ntasks\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n<TaskSurv:actg> (1151 x 13): ACTG 320\n* Target: time, status\n* Properties: -\n* Features (11):\n  - dbl (4): age, cd4, priorzdv, sexF\n  - fct (4): ivdrug, karnof, raceth, txgrp\n  - int (3): hemophil, strat2, tx\n\n[[2]]\n<TaskSurv:gbcs> (686 x 10): German Breast Cancer\n* Target: time, status\n* Properties: -\n* Features (8):\n  - dbl (4): age, estrg_recp, prog_recp, size\n  - int (4): grade, hormone, menopause, nodes\n\n[[3]]\n<TaskSurv:grace> (1000 x 8): GRACE 1000\n* Target: time, status\n* Properties: -\n* Features (6):\n  - dbl (4): age, los, revascdays, sysbp\n  - int (2): revasc, stchange\n\n[[4]]\n<TaskSurv:lung> (168 x 9): Lung Cancer\n* Target: time, status\n* Properties: -\n* Features (7):\n  - int (6): age, meal.cal, pat.karno, ph.ecog, ph.karno, wt.loss\n  - fct (1): sex\n\n[[5]]\n<TaskSurv:mgus> (176 x 9): MGUS\n* Target: time, status\n* Properties: -\n* Features (7):\n  - dbl (6): age, alb, creat, dxyr, hgb, mspike\n  - fct (1): sex\n```\n\n\n:::\n:::\n\n\n\n\nMany have categorical features (`fct`), which can be a bit tricky to handle for some learners, so we will take a shortcut and add a feature encoding `PipeOp` to the learners that need it.\nPipelines and preprocessing are very useful, and [the mlr3book](https://mlr3book.mlr-org.com/chapters/chapter9/preprocessing.html#factor-encoding) again has you covered!\n\nWe use the `po(\"encode\")` pipe operator to encode the factors as dummy-encoded variables (`method = \"treatment\"`) for the Cox model, and use the default (one-hot encoding) for the others.\nThe `%>>%` operator is used to chain `PipeOps` and learners together, and we wrap the pipeline in `as_learner` such that we can treat it as a learner just like the others.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreproc = po(\"encode\", method = \"treatment\")\n\nlearners = list(\n  cox = as_learner(preproc %>>% lrn(\"surv.coxph\",id = \"cph\")),\n  glmnet = as_learner(preproc %>>% lrn(\"surv.cv_glmnet\", alpha = 0.5)),\n  ranger = lrn(\"surv.ranger\", num.trees = 100),\n  aorsf = lrn(\"surv.aorsf\", n_tree = 100),\n  coxboost = as_learner(preproc %>>% lrn(\"surv.coxboost\", penalty = 100))\n)\n```\n:::\n\n\n\n\nA small convenience thing we can do here is to set IDs for the learners, which will make the output of further steps more readable:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n$cox\n[1] \"cox\"\n\n$glmnet\n[1] \"glmnet\"\n\n$ranger\n[1] \"ranger\"\n\n$aorsf\n[1] \"aorsf\"\n\n$coxboost\n[1] \"coxboost\"\n```\n\n\n:::\n:::\n\n\n\n\nMoving on to the benchmark, we create a design grid as before, only now we have multiple tasks.\nLuckily, `benchmark_grid()` can handle this for us by instantiating the resampling for each task, so we don't have to worry about this here!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndesign = benchmark_grid(\n  tasks = tasks,\n  learners = learners,\n  resamplings = rsmp(\"cv\", folds = 3)\n)\n\n# This might take a moment!\nbmr = benchmark(design, store_models = TRUE, store_backends = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:04:05.377] [mlr3] Running benchmark with 75 resampling iterations\nINFO  [17:04:05.380] [mlr3] Applying learner 'cox' on task 'actg' (iter 1/3)\nINFO  [17:04:05.437] [mlr3] Applying learner 'cox' on task 'actg' (iter 2/3)\nINFO  [17:04:05.503] [mlr3] Applying learner 'cox' on task 'actg' (iter 3/3)\nINFO  [17:04:05.558] [mlr3] Applying learner 'glmnet' on task 'actg' (iter 1/3)\nINFO  [17:04:05.876] [mlr3] Applying learner 'glmnet' on task 'actg' (iter 2/3)\nINFO  [17:04:06.207] [mlr3] Applying learner 'glmnet' on task 'actg' (iter 3/3)\nINFO  [17:04:06.518] [mlr3] Applying learner 'ranger' on task 'actg' (iter 1/3)\nINFO  [17:04:06.682] [mlr3] Applying learner 'ranger' on task 'actg' (iter 2/3)\nINFO  [17:04:06.862] [mlr3] Applying learner 'ranger' on task 'actg' (iter 3/3)\nINFO  [17:04:07.029] [mlr3] Applying learner 'aorsf' on task 'actg' (iter 1/3)\nINFO  [17:04:07.059] [mlr3] Applying learner 'aorsf' on task 'actg' (iter 2/3)\nINFO  [17:04:07.085] [mlr3] Applying learner 'aorsf' on task 'actg' (iter 3/3)\nINFO  [17:04:07.111] [mlr3] Applying learner 'coxboost' on task 'actg' (iter 1/3)\nINFO  [17:04:07.396] [mlr3] Applying learner 'coxboost' on task 'actg' (iter 2/3)\nINFO  [17:04:07.853] [mlr3] Applying learner 'coxboost' on task 'actg' (iter 3/3)\nINFO  [17:04:08.099] [mlr3] Applying learner 'cox' on task 'gbcs' (iter 1/3)\nINFO  [17:04:08.133] [mlr3] Applying learner 'cox' on task 'gbcs' (iter 2/3)\nINFO  [17:04:08.167] [mlr3] Applying learner 'cox' on task 'gbcs' (iter 3/3)\nINFO  [17:04:08.201] [mlr3] Applying learner 'glmnet' on task 'gbcs' (iter 1/3)\nINFO  [17:04:08.306] [mlr3] Applying learner 'glmnet' on task 'gbcs' (iter 2/3)\nINFO  [17:04:08.396] [mlr3] Applying learner 'glmnet' on task 'gbcs' (iter 3/3)\nINFO  [17:04:08.489] [mlr3] Applying learner 'ranger' on task 'gbcs' (iter 1/3)\nINFO  [17:04:08.645] [mlr3] Applying learner 'ranger' on task 'gbcs' (iter 2/3)\nINFO  [17:04:08.803] [mlr3] Applying learner 'ranger' on task 'gbcs' (iter 3/3)\nINFO  [17:04:08.974] [mlr3] Applying learner 'aorsf' on task 'gbcs' (iter 1/3)\nINFO  [17:04:08.999] [mlr3] Applying learner 'aorsf' on task 'gbcs' (iter 2/3)\nINFO  [17:04:09.024] [mlr3] Applying learner 'aorsf' on task 'gbcs' (iter 3/3)\nINFO  [17:04:09.051] [mlr3] Applying learner 'coxboost' on task 'gbcs' (iter 1/3)\nINFO  [17:04:09.436] [mlr3] Applying learner 'coxboost' on task 'gbcs' (iter 2/3)\nINFO  [17:04:09.624] [mlr3] Applying learner 'coxboost' on task 'gbcs' (iter 3/3)\nINFO  [17:04:09.817] [mlr3] Applying learner 'cox' on task 'grace' (iter 1/3)\nINFO  [17:04:09.848] [mlr3] Applying learner 'cox' on task 'grace' (iter 2/3)\nINFO  [17:04:09.880] [mlr3] Applying learner 'cox' on task 'grace' (iter 3/3)\nINFO  [17:04:09.913] [mlr3] Applying learner 'glmnet' on task 'grace' (iter 1/3)\nINFO  [17:04:10.050] [mlr3] Applying learner 'glmnet' on task 'grace' (iter 2/3)\nINFO  [17:04:10.200] [mlr3] Applying learner 'glmnet' on task 'grace' (iter 3/3)\nINFO  [17:04:10.336] [mlr3] Applying learner 'ranger' on task 'grace' (iter 1/3)\nINFO  [17:04:10.552] [mlr3] Applying learner 'ranger' on task 'grace' (iter 2/3)\nINFO  [17:04:10.755] [mlr3] Applying learner 'ranger' on task 'grace' (iter 3/3)\nINFO  [17:04:10.977] [mlr3] Applying learner 'aorsf' on task 'grace' (iter 1/3)\nINFO  [17:04:11.035] [mlr3] Applying learner 'aorsf' on task 'grace' (iter 2/3)\nINFO  [17:04:11.076] [mlr3] Applying learner 'aorsf' on task 'grace' (iter 3/3)\nINFO  [17:04:11.131] [mlr3] Applying learner 'coxboost' on task 'grace' (iter 1/3)\nINFO  [17:04:11.574] [mlr3] Applying learner 'coxboost' on task 'grace' (iter 2/3)\nINFO  [17:04:11.906] [mlr3] Applying learner 'coxboost' on task 'grace' (iter 3/3)\nINFO  [17:04:12.482] [mlr3] Applying learner 'cox' on task 'lung' (iter 1/3)\nINFO  [17:04:12.534] [mlr3] Applying learner 'cox' on task 'lung' (iter 2/3)\nINFO  [17:04:12.582] [mlr3] Applying learner 'cox' on task 'lung' (iter 3/3)\nINFO  [17:04:12.634] [mlr3] Applying learner 'glmnet' on task 'lung' (iter 1/3)\nINFO  [17:04:12.746] [mlr3] Applying learner 'glmnet' on task 'lung' (iter 2/3)\nINFO  [17:04:12.830] [mlr3] Applying learner 'glmnet' on task 'lung' (iter 3/3)\nINFO  [17:04:12.912] [mlr3] Applying learner 'ranger' on task 'lung' (iter 1/3)\nINFO  [17:04:12.950] [mlr3] Applying learner 'ranger' on task 'lung' (iter 2/3)\nINFO  [17:04:12.988] [mlr3] Applying learner 'ranger' on task 'lung' (iter 3/3)\nINFO  [17:04:13.027] [mlr3] Applying learner 'aorsf' on task 'lung' (iter 1/3)\nINFO  [17:04:13.046] [mlr3] Applying learner 'aorsf' on task 'lung' (iter 2/3)\nINFO  [17:04:13.064] [mlr3] Applying learner 'aorsf' on task 'lung' (iter 3/3)\nINFO  [17:04:13.082] [mlr3] Applying learner 'coxboost' on task 'lung' (iter 1/3)\nINFO  [17:04:13.189] [mlr3] Applying learner 'coxboost' on task 'lung' (iter 2/3)\nINFO  [17:04:13.300] [mlr3] Applying learner 'coxboost' on task 'lung' (iter 3/3)\nINFO  [17:04:13.401] [mlr3] Applying learner 'cox' on task 'mgus' (iter 1/3)\nINFO  [17:04:13.460] [mlr3] Applying learner 'cox' on task 'mgus' (iter 2/3)\nINFO  [17:04:13.501] [mlr3] Applying learner 'cox' on task 'mgus' (iter 3/3)\nINFO  [17:04:13.543] [mlr3] Applying learner 'glmnet' on task 'mgus' (iter 1/3)\nINFO  [17:04:13.610] [mlr3] Applying learner 'glmnet' on task 'mgus' (iter 2/3)\nINFO  [17:04:13.685] [mlr3] Applying learner 'glmnet' on task 'mgus' (iter 3/3)\nINFO  [17:04:13.753] [mlr3] Applying learner 'ranger' on task 'mgus' (iter 1/3)\nINFO  [17:04:13.797] [mlr3] Applying learner 'ranger' on task 'mgus' (iter 2/3)\nINFO  [17:04:13.845] [mlr3] Applying learner 'ranger' on task 'mgus' (iter 3/3)\nINFO  [17:04:13.891] [mlr3] Applying learner 'aorsf' on task 'mgus' (iter 1/3)\nINFO  [17:04:13.910] [mlr3] Applying learner 'aorsf' on task 'mgus' (iter 2/3)\nINFO  [17:04:13.929] [mlr3] Applying learner 'aorsf' on task 'mgus' (iter 3/3)\nINFO  [17:04:13.947] [mlr3] Applying learner 'coxboost' on task 'mgus' (iter 1/3)\nINFO  [17:04:14.078] [mlr3] Applying learner 'coxboost' on task 'mgus' (iter 2/3)\nINFO  [17:04:14.213] [mlr3] Applying learner 'coxboost' on task 'mgus' (iter 3/3)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, : Loglik converged before variable  7,17 ; coefficient may be infinite. \nThis happened PipeOp cph's $train()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, : Loglik converged before variable  7,16,17,18 ; coefficient may be infinite. \nThis happened PipeOp cph's $train()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, : Loglik converged before variable  8,18 ; coefficient may be infinite. \nThis happened PipeOp cph's $train()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nINFO  [17:04:14.398] [mlr3] Finished benchmark\n```\n\n\n:::\n:::\n\n\n\n\nWe pick the IBS again and aggregate the results:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasure = msr(\"surv.brier\", id = \"ibs\")\n\nbmr$aggregate(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       nr task_id learner_id resampling_id iters        ibs\n    <int>  <char>     <char>        <char> <int>      <num>\n 1:     1    actg        cox            cv     3 0.05978873\n 2:     2    actg     glmnet            cv     3 0.06041163\n 3:     3    actg     ranger            cv     3 0.06088070\n 4:     4    actg      aorsf            cv     3 0.05837878\n 5:     5    actg   coxboost            cv     3 0.05906567\n 6:     6    gbcs        cox            cv     3 0.12084849\n 7:     7    gbcs     glmnet            cv     3 0.13339647\n 8:     8    gbcs     ranger            cv     3 0.12825468\n 9:     9    gbcs      aorsf            cv     3 0.11956394\n10:    10    gbcs   coxboost            cv     3 0.12084801\n11:    11   grace        cox            cv     3 0.09749663\n12:    12   grace     glmnet            cv     3 0.10381720\n13:    13   grace     ranger            cv     3 0.10787449\n14:    14   grace      aorsf            cv     3 0.09184122\n15:    15   grace   coxboost            cv     3 0.09749658\n [ reached getOption(\"max.print\") -- omitted 11 rows ]\nHidden columns: resample_result\n```\n\n\n:::\n:::\n\n\n\n\n### Statistical analysis {-}\n\nRather than just computing average scores, we can leverage `mlr3benchmark` for additional analysis steps, including a statistical analysis of the results.\nThe starting point is to convert the benchmark result (`bmr`) to an aggregated benchmark result (`bma`), which is a more convenient format for further analysis:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3benchmark)\nbma = as_benchmark_aggr(bmr, meas = measure)\nbma\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<BenchmarkAggr> of 25 rows with 5 tasks, 5 learners and 1 measure\n    task_id learner_id        ibs\n     <fctr>     <fctr>      <num>\n 1:    actg        cox 0.05978873\n 2:    actg     glmnet 0.06041163\n 3:    actg     ranger 0.06088070\n 4:    actg      aorsf 0.05837878\n 5:    actg   coxboost 0.05906567\n 6:    gbcs        cox 0.12084849\n 7:    gbcs     glmnet 0.13339647\n 8:    gbcs     ranger 0.12825468\n 9:    gbcs      aorsf 0.11956394\n10:    gbcs   coxboost 0.12084801\n11:   grace        cox 0.09749663\n12:   grace     glmnet 0.10381720\n13:   grace     ranger 0.10787449\n14:   grace      aorsf 0.09184122\n15:   grace   coxboost 0.09749658\n16:    lung        cox 0.15922764\n17:    lung     glmnet 0.14848136\n18:    lung     ranger 0.17343481\n19:    lung      aorsf 0.15450793\n20:    lung   coxboost 0.15905475\n21:    mgus        cox 0.12491045\n22:    mgus     glmnet 0.13442554\n23:    mgus     ranger 0.14613226\n24:    mgus      aorsf 0.13580314\n25:    mgus   coxboost 0.12491102\n    task_id learner_id        ibs\n```\n\n\n:::\n:::\n\n\n\n\n\nThis brings with it a few more `autoplot` methods, see `?autoplot.BenchmarkAggr`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(bma, type = \"box\", meas = \"ibs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bma-box-1.png){width=672}\n:::\n:::\n\n\n\n\nFor the statistical analysis, we can use a simple rank-based analysis with a global Friedman test to see if there are significant differences between the learners:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbma$friedman_test()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tFriedman rank sum test\n\ndata:  ibs and learner_id and task_id\nFriedman chi-squared = 11.04, df = 4, p-value = 0.02612\n```\n\n\n:::\n:::\n\n\n\n\nThe corresponding post-hoc test for all pairwise comparison can be performed as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbma$friedman_posthoc()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n\tPairwise comparisons using Nemenyi-Wilcoxon-Wilcox all-pairs test for a two-way balanced complete block design\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\ndata: ibs and learner_id and task_id\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         cox   glmnet ranger aorsf\nglmnet   0.975 -      -      -    \nranger   0.266 0.628  -      -    \naorsf    0.855 0.497  0.023  -    \ncoxboost 0.975 0.751  0.070  0.995\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nP value adjustment method: single-step\n```\n\n\n:::\n:::\n\n\n\n\nWhich is also available graphically:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(bma, type = \"fn\", meas = \"ibs\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bma-friedman-1.png){width=672}\n:::\n:::\n\n\n\n\n## Conclusion\n\nWe have conducted a tiny benchmark experiment on a few survival tasks using a few learners --- a good starting point for further exploration!\nAdvanced topics we did not cover in more detail include tuning and more advanced pipelines, but we hope you got a good overview of the capabilities of `mlr3proba` and `mlr3` in general.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}